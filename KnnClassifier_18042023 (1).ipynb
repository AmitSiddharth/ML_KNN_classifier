{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac8deee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde6c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cancer.csv')\n",
    "pd.options.display.max_rows=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02dd7fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis(1=m, 0=b)</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.880</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.060</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.36820</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>...</td>\n",
       "      <td>19.190</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>...</td>\n",
       "      <td>20.420</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.13960</td>\n",
       "      <td>0.56090</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>...</td>\n",
       "      <td>16.840</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>15.030</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>...</td>\n",
       "      <td>17.460</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>19.070</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>...</td>\n",
       "      <td>27.320</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>...</td>\n",
       "      <td>18.070</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.59540</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>29.170</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>...</td>\n",
       "      <td>26.460</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>...</td>\n",
       "      <td>22.250</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.39490</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>17.620</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>...</td>\n",
       "      <td>21.310</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.16830</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>...</td>\n",
       "      <td>20.270</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.16410</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.09875</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>...</td>\n",
       "      <td>20.010</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.28120</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>18.630</td>\n",
       "      <td>25.11</td>\n",
       "      <td>124.80</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.18870</td>\n",
       "      <td>0.23190</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>...</td>\n",
       "      <td>23.150</td>\n",
       "      <td>34.01</td>\n",
       "      <td>160.50</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.42570</td>\n",
       "      <td>0.61330</td>\n",
       "      <td>0.18480</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.09782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>11.840</td>\n",
       "      <td>18.70</td>\n",
       "      <td>77.93</td>\n",
       "      <td>440.6</td>\n",
       "      <td>0.11090</td>\n",
       "      <td>0.15160</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.051820</td>\n",
       "      <td>0.2301</td>\n",
       "      <td>...</td>\n",
       "      <td>16.820</td>\n",
       "      <td>28.12</td>\n",
       "      <td>119.40</td>\n",
       "      <td>888.7</td>\n",
       "      <td>0.16370</td>\n",
       "      <td>0.57750</td>\n",
       "      <td>0.69560</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.4761</td>\n",
       "      <td>0.14020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>17.020</td>\n",
       "      <td>23.98</td>\n",
       "      <td>112.80</td>\n",
       "      <td>899.3</td>\n",
       "      <td>0.11970</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.24170</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.2248</td>\n",
       "      <td>...</td>\n",
       "      <td>20.880</td>\n",
       "      <td>32.09</td>\n",
       "      <td>136.10</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>0.16340</td>\n",
       "      <td>0.35590</td>\n",
       "      <td>0.55880</td>\n",
       "      <td>0.18470</td>\n",
       "      <td>0.3530</td>\n",
       "      <td>0.08482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>19.270</td>\n",
       "      <td>26.47</td>\n",
       "      <td>127.90</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>0.09401</td>\n",
       "      <td>0.17190</td>\n",
       "      <td>0.16570</td>\n",
       "      <td>0.075930</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>...</td>\n",
       "      <td>24.150</td>\n",
       "      <td>30.90</td>\n",
       "      <td>161.40</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>0.15090</td>\n",
       "      <td>0.65900</td>\n",
       "      <td>0.60910</td>\n",
       "      <td>0.17850</td>\n",
       "      <td>0.3672</td>\n",
       "      <td>0.11230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>16.130</td>\n",
       "      <td>17.88</td>\n",
       "      <td>107.00</td>\n",
       "      <td>807.2</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.15590</td>\n",
       "      <td>0.13540</td>\n",
       "      <td>0.077520</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>...</td>\n",
       "      <td>20.210</td>\n",
       "      <td>27.26</td>\n",
       "      <td>132.70</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.14460</td>\n",
       "      <td>0.58040</td>\n",
       "      <td>0.52740</td>\n",
       "      <td>0.18640</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.12330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>16.740</td>\n",
       "      <td>21.59</td>\n",
       "      <td>110.10</td>\n",
       "      <td>869.5</td>\n",
       "      <td>0.09610</td>\n",
       "      <td>0.13360</td>\n",
       "      <td>0.13480</td>\n",
       "      <td>0.060180</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>...</td>\n",
       "      <td>20.010</td>\n",
       "      <td>29.02</td>\n",
       "      <td>133.50</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>0.15630</td>\n",
       "      <td>0.38350</td>\n",
       "      <td>0.54090</td>\n",
       "      <td>0.18130</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>0.08633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>14.250</td>\n",
       "      <td>21.72</td>\n",
       "      <td>93.63</td>\n",
       "      <td>633.0</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.10980</td>\n",
       "      <td>0.13190</td>\n",
       "      <td>0.055980</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>15.890</td>\n",
       "      <td>30.36</td>\n",
       "      <td>116.20</td>\n",
       "      <td>799.6</td>\n",
       "      <td>0.14460</td>\n",
       "      <td>0.42380</td>\n",
       "      <td>0.51860</td>\n",
       "      <td>0.14470</td>\n",
       "      <td>0.3591</td>\n",
       "      <td>0.10140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>14.990</td>\n",
       "      <td>25.20</td>\n",
       "      <td>95.54</td>\n",
       "      <td>698.8</td>\n",
       "      <td>0.09387</td>\n",
       "      <td>0.05131</td>\n",
       "      <td>0.02398</td>\n",
       "      <td>0.028990</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>...</td>\n",
       "      <td>14.990</td>\n",
       "      <td>25.20</td>\n",
       "      <td>95.54</td>\n",
       "      <td>698.8</td>\n",
       "      <td>0.09387</td>\n",
       "      <td>0.05131</td>\n",
       "      <td>0.02398</td>\n",
       "      <td>0.02899</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.05504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>13.480</td>\n",
       "      <td>20.82</td>\n",
       "      <td>88.40</td>\n",
       "      <td>559.2</td>\n",
       "      <td>0.10160</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.054390</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>...</td>\n",
       "      <td>15.530</td>\n",
       "      <td>26.02</td>\n",
       "      <td>107.30</td>\n",
       "      <td>740.4</td>\n",
       "      <td>0.16100</td>\n",
       "      <td>0.42250</td>\n",
       "      <td>0.50300</td>\n",
       "      <td>0.22580</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.10710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>13.440</td>\n",
       "      <td>21.58</td>\n",
       "      <td>86.18</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.08162</td>\n",
       "      <td>0.06031</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>...</td>\n",
       "      <td>15.930</td>\n",
       "      <td>30.25</td>\n",
       "      <td>102.50</td>\n",
       "      <td>787.9</td>\n",
       "      <td>0.10940</td>\n",
       "      <td>0.20430</td>\n",
       "      <td>0.20850</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>0.07146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>10.950</td>\n",
       "      <td>21.35</td>\n",
       "      <td>71.90</td>\n",
       "      <td>371.1</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.056690</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>...</td>\n",
       "      <td>12.840</td>\n",
       "      <td>35.34</td>\n",
       "      <td>87.22</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.19090</td>\n",
       "      <td>0.26980</td>\n",
       "      <td>0.40230</td>\n",
       "      <td>0.14240</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.09606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>19.070</td>\n",
       "      <td>24.81</td>\n",
       "      <td>128.30</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>0.09081</td>\n",
       "      <td>0.21900</td>\n",
       "      <td>0.21070</td>\n",
       "      <td>0.099610</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>...</td>\n",
       "      <td>24.090</td>\n",
       "      <td>33.17</td>\n",
       "      <td>177.40</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>0.12470</td>\n",
       "      <td>0.74440</td>\n",
       "      <td>0.72420</td>\n",
       "      <td>0.24930</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>0.10380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>13.280</td>\n",
       "      <td>20.28</td>\n",
       "      <td>87.32</td>\n",
       "      <td>545.2</td>\n",
       "      <td>0.10410</td>\n",
       "      <td>0.14360</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.061580</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>...</td>\n",
       "      <td>17.380</td>\n",
       "      <td>28.00</td>\n",
       "      <td>113.10</td>\n",
       "      <td>907.2</td>\n",
       "      <td>0.15300</td>\n",
       "      <td>0.37240</td>\n",
       "      <td>0.36640</td>\n",
       "      <td>0.14920</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.10270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>13.170</td>\n",
       "      <td>21.81</td>\n",
       "      <td>85.42</td>\n",
       "      <td>531.5</td>\n",
       "      <td>0.09714</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.08259</td>\n",
       "      <td>0.052520</td>\n",
       "      <td>0.1746</td>\n",
       "      <td>...</td>\n",
       "      <td>16.230</td>\n",
       "      <td>29.89</td>\n",
       "      <td>105.50</td>\n",
       "      <td>740.7</td>\n",
       "      <td>0.15030</td>\n",
       "      <td>0.39040</td>\n",
       "      <td>0.37280</td>\n",
       "      <td>0.16070</td>\n",
       "      <td>0.3693</td>\n",
       "      <td>0.09618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>18.650</td>\n",
       "      <td>17.60</td>\n",
       "      <td>123.70</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.16860</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.1907</td>\n",
       "      <td>...</td>\n",
       "      <td>22.820</td>\n",
       "      <td>21.32</td>\n",
       "      <td>150.60</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.16790</td>\n",
       "      <td>0.50900</td>\n",
       "      <td>0.73450</td>\n",
       "      <td>0.23780</td>\n",
       "      <td>0.3799</td>\n",
       "      <td>0.09185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>8.964</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>13.170</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>...</td>\n",
       "      <td>15.670</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.41660</td>\n",
       "      <td>0.50060</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>12.050</td>\n",
       "      <td>14.63</td>\n",
       "      <td>78.04</td>\n",
       "      <td>449.3</td>\n",
       "      <td>0.10310</td>\n",
       "      <td>0.09092</td>\n",
       "      <td>0.06592</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>...</td>\n",
       "      <td>13.760</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.88</td>\n",
       "      <td>582.6</td>\n",
       "      <td>0.14940</td>\n",
       "      <td>0.21560</td>\n",
       "      <td>0.30500</td>\n",
       "      <td>0.06548</td>\n",
       "      <td>0.2747</td>\n",
       "      <td>0.08301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>13.490</td>\n",
       "      <td>22.30</td>\n",
       "      <td>86.91</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.08752</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04751</td>\n",
       "      <td>0.033840</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>15.150</td>\n",
       "      <td>31.82</td>\n",
       "      <td>99.00</td>\n",
       "      <td>698.8</td>\n",
       "      <td>0.11620</td>\n",
       "      <td>0.17110</td>\n",
       "      <td>0.22820</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.06917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis(1=m, 0=b)  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0                     1       17.990         10.38          122.80     1001.0   \n",
       "1                     1       20.570         17.77          132.90     1326.0   \n",
       "2                     1       19.690         21.25          130.00     1203.0   \n",
       "3                     1       11.420         20.38           77.58      386.1   \n",
       "4                     1       20.290         14.34          135.10     1297.0   \n",
       "5                     1       12.450         15.70           82.57      477.1   \n",
       "6                     1       18.250         19.98          119.60     1040.0   \n",
       "7                     1       13.710         20.83           90.20      577.9   \n",
       "8                     1       13.000         21.82           87.50      519.8   \n",
       "9                     1       12.460         24.04           83.97      475.9   \n",
       "10                    1       16.020         23.24          102.70      797.8   \n",
       "11                    1       15.780         17.89          103.60      781.0   \n",
       "12                    1       19.170         24.80          132.40     1123.0   \n",
       "13                    1       15.850         23.95          103.70      782.7   \n",
       "14                    1       13.730         22.61           93.60      578.3   \n",
       "15                    1       14.540         27.54           96.73      658.8   \n",
       "16                    1       14.680         20.13           94.74      684.5   \n",
       "17                    1       16.130         20.68          108.10      798.8   \n",
       "18                    1       19.810         22.15          130.00     1260.0   \n",
       "19                    0       13.540         14.36           87.46      566.3   \n",
       "20                    0       13.080         15.71           85.63      520.0   \n",
       "21                    0        9.504         12.44           60.34      273.9   \n",
       "22                    1       15.340         14.26          102.50      704.4   \n",
       "23                    1       21.160         23.04          137.20     1404.0   \n",
       "24                    1       16.650         21.38          110.00      904.6   \n",
       "25                    1       17.140         16.40          116.00      912.7   \n",
       "26                    1       14.580         21.53           97.41      644.8   \n",
       "27                    1       18.610         20.25          122.10     1094.0   \n",
       "28                    1       15.300         25.27          102.40      732.4   \n",
       "29                    1       17.570         15.05          115.00      955.1   \n",
       "30                    1       18.630         25.11          124.80     1088.0   \n",
       "31                    1       11.840         18.70           77.93      440.6   \n",
       "32                    1       17.020         23.98          112.80      899.3   \n",
       "33                    1       19.270         26.47          127.90     1162.0   \n",
       "34                    1       16.130         17.88          107.00      807.2   \n",
       "35                    1       16.740         21.59          110.10      869.5   \n",
       "36                    1       14.250         21.72           93.63      633.0   \n",
       "37                    0       13.030         18.42           82.61      523.8   \n",
       "38                    1       14.990         25.20           95.54      698.8   \n",
       "39                    1       13.480         20.82           88.40      559.2   \n",
       "40                    1       13.440         21.58           86.18      563.0   \n",
       "41                    1       10.950         21.35           71.90      371.1   \n",
       "42                    1       19.070         24.81          128.30     1104.0   \n",
       "43                    1       13.280         20.28           87.32      545.2   \n",
       "44                    1       13.170         21.81           85.42      531.5   \n",
       "45                    1       18.650         17.60          123.70     1076.0   \n",
       "46                    0        8.196         16.84           51.71      201.9   \n",
       "47                    1       13.170         18.66           85.98      534.6   \n",
       "48                    0       12.050         14.63           78.04      449.3   \n",
       "49                    0       13.490         22.30           86.91      561.0   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.11840           0.27760         0.30010             0.147100   \n",
       "1           0.08474           0.07864         0.08690             0.070170   \n",
       "2           0.10960           0.15990         0.19740             0.127900   \n",
       "3           0.14250           0.28390         0.24140             0.105200   \n",
       "4           0.10030           0.13280         0.19800             0.104300   \n",
       "5           0.12780           0.17000         0.15780             0.080890   \n",
       "6           0.09463           0.10900         0.11270             0.074000   \n",
       "7           0.11890           0.16450         0.09366             0.059850   \n",
       "8           0.12730           0.19320         0.18590             0.093530   \n",
       "9           0.11860           0.23960         0.22730             0.085430   \n",
       "10          0.08206           0.06669         0.03299             0.033230   \n",
       "11          0.09710           0.12920         0.09954             0.066060   \n",
       "12          0.09740           0.24580         0.20650             0.111800   \n",
       "13          0.08401           0.10020         0.09938             0.053640   \n",
       "14          0.11310           0.22930         0.21280             0.080250   \n",
       "15          0.11390           0.15950         0.16390             0.073640   \n",
       "16          0.09867           0.07200         0.07395             0.052590   \n",
       "17          0.11700           0.20220         0.17220             0.102800   \n",
       "18          0.09831           0.10270         0.14790             0.094980   \n",
       "19          0.09779           0.08129         0.06664             0.047810   \n",
       "20          0.10750           0.12700         0.04568             0.031100   \n",
       "21          0.10240           0.06492         0.02956             0.020760   \n",
       "22          0.10730           0.21350         0.20770             0.097560   \n",
       "23          0.09428           0.10220         0.10970             0.086320   \n",
       "24          0.11210           0.14570         0.15250             0.091700   \n",
       "25          0.11860           0.22760         0.22290             0.140100   \n",
       "26          0.10540           0.18680         0.14250             0.087830   \n",
       "27          0.09440           0.10660         0.14900             0.077310   \n",
       "28          0.10820           0.16970         0.16830             0.087510   \n",
       "29          0.09847           0.11570         0.09875             0.079530   \n",
       "30          0.10640           0.18870         0.23190             0.124400   \n",
       "31          0.11090           0.15160         0.12180             0.051820   \n",
       "32          0.11970           0.14960         0.24170             0.120300   \n",
       "33          0.09401           0.17190         0.16570             0.075930   \n",
       "34          0.10400           0.15590         0.13540             0.077520   \n",
       "35          0.09610           0.13360         0.13480             0.060180   \n",
       "36          0.09823           0.10980         0.13190             0.055980   \n",
       "37          0.08983           0.03766         0.02562             0.029230   \n",
       "38          0.09387           0.05131         0.02398             0.028990   \n",
       "39          0.10160           0.12550         0.10630             0.054390   \n",
       "40          0.08162           0.06031         0.03110             0.020310   \n",
       "41          0.12270           0.12180         0.10440             0.056690   \n",
       "42          0.09081           0.21900         0.21070             0.099610   \n",
       "43          0.10410           0.14360         0.09847             0.061580   \n",
       "44          0.09714           0.10470         0.08259             0.052520   \n",
       "45          0.10990           0.16860         0.19740             0.100900   \n",
       "46          0.08600           0.05943         0.01588             0.005917   \n",
       "47          0.11580           0.12310         0.12260             0.073400   \n",
       "48          0.10310           0.09092         0.06592             0.027490   \n",
       "49          0.08752           0.07698         0.04751             0.033840   \n",
       "\n",
       "    symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0          0.2419  ...        25.380          17.33           184.60   \n",
       "1          0.1812  ...        24.990          23.41           158.80   \n",
       "2          0.2069  ...        23.570          25.53           152.50   \n",
       "3          0.2597  ...        14.910          26.50            98.87   \n",
       "4          0.1809  ...        22.540          16.67           152.20   \n",
       "5          0.2087  ...        15.470          23.75           103.40   \n",
       "6          0.1794  ...        22.880          27.66           153.20   \n",
       "7          0.2196  ...        17.060          28.14           110.60   \n",
       "8          0.2350  ...        15.490          30.73           106.20   \n",
       "9          0.2030  ...        15.090          40.68            97.65   \n",
       "10         0.1528  ...        19.190          33.88           123.80   \n",
       "11         0.1842  ...        20.420          27.28           136.50   \n",
       "12         0.2397  ...        20.960          29.94           151.70   \n",
       "13         0.1847  ...        16.840          27.66           112.00   \n",
       "14         0.2069  ...        15.030          32.01           108.80   \n",
       "15         0.2303  ...        17.460          37.13           124.10   \n",
       "16         0.1586  ...        19.070          30.88           123.40   \n",
       "17         0.2164  ...        20.960          31.48           136.80   \n",
       "18         0.1582  ...        27.320          30.88           186.80   \n",
       "19         0.1885  ...        15.110          19.26            99.70   \n",
       "20         0.1967  ...        14.500          20.49            96.09   \n",
       "21         0.1815  ...        10.230          15.66            65.13   \n",
       "22         0.2521  ...        18.070          19.08           125.10   \n",
       "23         0.1769  ...        29.170          35.59           188.00   \n",
       "24         0.1995  ...        26.460          31.56           177.00   \n",
       "25         0.3040  ...        22.250          21.40           152.40   \n",
       "26         0.2252  ...        17.620          33.21           122.40   \n",
       "27         0.1697  ...        21.310          27.26           139.90   \n",
       "28         0.1926  ...        20.270          36.71           149.30   \n",
       "29         0.1739  ...        20.010          19.52           134.90   \n",
       "30         0.2183  ...        23.150          34.01           160.50   \n",
       "31         0.2301  ...        16.820          28.12           119.40   \n",
       "32         0.2248  ...        20.880          32.09           136.10   \n",
       "33         0.1853  ...        24.150          30.90           161.40   \n",
       "34         0.1998  ...        20.210          27.26           132.70   \n",
       "35         0.1896  ...        20.010          29.02           133.50   \n",
       "36         0.1885  ...        15.890          30.36           116.20   \n",
       "37         0.1467  ...        13.300          22.81            84.46   \n",
       "38         0.1565  ...        14.990          25.20            95.54   \n",
       "39         0.1720  ...        15.530          26.02           107.30   \n",
       "40         0.1784  ...        15.930          30.25           102.50   \n",
       "41         0.1895  ...        12.840          35.34            87.22   \n",
       "42         0.2310  ...        24.090          33.17           177.40   \n",
       "43         0.1974  ...        17.380          28.00           113.10   \n",
       "44         0.1746  ...        16.230          29.89           105.50   \n",
       "45         0.1907  ...        22.820          21.32           150.60   \n",
       "46         0.1769  ...         8.964          21.96            57.26   \n",
       "47         0.2128  ...        15.670          27.95           102.80   \n",
       "48         0.1675  ...        13.760          20.70            89.88   \n",
       "49         0.1809  ...        15.150          31.82            99.00   \n",
       "\n",
       "    area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       2019.0           0.16220            0.66560          0.71190   \n",
       "1       1956.0           0.12380            0.18660          0.24160   \n",
       "2       1709.0           0.14440            0.42450          0.45040   \n",
       "3        567.7           0.20980            0.86630          0.68690   \n",
       "4       1575.0           0.13740            0.20500          0.40000   \n",
       "5        741.6           0.17910            0.52490          0.53550   \n",
       "6       1606.0           0.14420            0.25760          0.37840   \n",
       "7        897.0           0.16540            0.36820          0.26780   \n",
       "8        739.3           0.17030            0.54010          0.53900   \n",
       "9        711.4           0.18530            1.05800          1.10500   \n",
       "10      1150.0           0.11810            0.15510          0.14590   \n",
       "11      1299.0           0.13960            0.56090          0.39650   \n",
       "12      1332.0           0.10370            0.39030          0.36390   \n",
       "13       876.5           0.11310            0.19240          0.23220   \n",
       "14       697.7           0.16510            0.77250          0.69430   \n",
       "15       943.2           0.16780            0.65770          0.70260   \n",
       "16      1138.0           0.14640            0.18710          0.29140   \n",
       "17      1315.0           0.17890            0.42330          0.47840   \n",
       "18      2398.0           0.15120            0.31500          0.53720   \n",
       "19       711.2           0.14400            0.17730          0.23900   \n",
       "20       630.5           0.13120            0.27760          0.18900   \n",
       "21       314.9           0.13240            0.11480          0.08867   \n",
       "22       980.9           0.13900            0.59540          0.63050   \n",
       "23      2615.0           0.14010            0.26000          0.31550   \n",
       "24      2215.0           0.18050            0.35780          0.46950   \n",
       "25      1461.0           0.15450            0.39490          0.38530   \n",
       "26       896.9           0.15250            0.66430          0.55390   \n",
       "27      1403.0           0.13380            0.21170          0.34460   \n",
       "28      1269.0           0.16410            0.61100          0.63350   \n",
       "29      1227.0           0.12550            0.28120          0.24890   \n",
       "30      1670.0           0.14910            0.42570          0.61330   \n",
       "31       888.7           0.16370            0.57750          0.69560   \n",
       "32      1344.0           0.16340            0.35590          0.55880   \n",
       "33      1813.0           0.15090            0.65900          0.60910   \n",
       "34      1261.0           0.14460            0.58040          0.52740   \n",
       "35      1229.0           0.15630            0.38350          0.54090   \n",
       "36       799.6           0.14460            0.42380          0.51860   \n",
       "37       545.9           0.09701            0.04619          0.04833   \n",
       "38       698.8           0.09387            0.05131          0.02398   \n",
       "39       740.4           0.16100            0.42250          0.50300   \n",
       "40       787.9           0.10940            0.20430          0.20850   \n",
       "41       514.0           0.19090            0.26980          0.40230   \n",
       "42      1651.0           0.12470            0.74440          0.72420   \n",
       "43       907.2           0.15300            0.37240          0.36640   \n",
       "44       740.7           0.15030            0.39040          0.37280   \n",
       "45      1567.0           0.16790            0.50900          0.73450   \n",
       "46       242.2           0.12970            0.13570          0.06880   \n",
       "47       759.4           0.17860            0.41660          0.50060   \n",
       "48       582.6           0.14940            0.21560          0.30500   \n",
       "49       698.8           0.11620            0.17110          0.22820   \n",
       "\n",
       "    concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.26540          0.4601                  0.11890  \n",
       "1                0.18600          0.2750                  0.08902  \n",
       "2                0.24300          0.3613                  0.08758  \n",
       "3                0.25750          0.6638                  0.17300  \n",
       "4                0.16250          0.2364                  0.07678  \n",
       "5                0.17410          0.3985                  0.12440  \n",
       "6                0.19320          0.3063                  0.08368  \n",
       "7                0.15560          0.3196                  0.11510  \n",
       "8                0.20600          0.4378                  0.10720  \n",
       "9                0.22100          0.4366                  0.20750  \n",
       "10               0.09975          0.2948                  0.08452  \n",
       "11               0.18100          0.3792                  0.10480  \n",
       "12               0.17670          0.3176                  0.10230  \n",
       "13               0.11190          0.2809                  0.06287  \n",
       "14               0.22080          0.3596                  0.14310  \n",
       "15               0.17120          0.4218                  0.13410  \n",
       "16               0.16090          0.3029                  0.08216  \n",
       "17               0.20730          0.3706                  0.11420  \n",
       "18               0.23880          0.2768                  0.07615  \n",
       "19               0.12880          0.2977                  0.07259  \n",
       "20               0.07283          0.3184                  0.08183  \n",
       "21               0.06227          0.2450                  0.07773  \n",
       "22               0.23930          0.4667                  0.09946  \n",
       "23               0.20090          0.2822                  0.07526  \n",
       "24               0.20950          0.3613                  0.09564  \n",
       "25               0.25500          0.4066                  0.10590  \n",
       "26               0.27010          0.4264                  0.12750  \n",
       "27               0.14900          0.2341                  0.07421  \n",
       "28               0.20240          0.4027                  0.09876  \n",
       "29               0.14560          0.2756                  0.07919  \n",
       "30               0.18480          0.3444                  0.09782  \n",
       "31               0.15460          0.4761                  0.14020  \n",
       "32               0.18470          0.3530                  0.08482  \n",
       "33               0.17850          0.3672                  0.11230  \n",
       "34               0.18640          0.4270                  0.12330  \n",
       "35               0.18130          0.4863                  0.08633  \n",
       "36               0.14470          0.3591                  0.10140  \n",
       "37               0.05013          0.1987                  0.06169  \n",
       "38               0.02899          0.1565                  0.05504  \n",
       "39               0.22580          0.2807                  0.10710  \n",
       "40               0.11120          0.2994                  0.07146  \n",
       "41               0.14240          0.2964                  0.09606  \n",
       "42               0.24930          0.4670                  0.10380  \n",
       "43               0.14920          0.3739                  0.10270  \n",
       "44               0.16070          0.3693                  0.09618  \n",
       "45               0.23780          0.3799                  0.09185  \n",
       "46               0.02564          0.3105                  0.07409  \n",
       "47               0.20880          0.3900                  0.11790  \n",
       "48               0.06548          0.2747                  0.08301  \n",
       "49               0.12820          0.2871                  0.06917  \n",
       "\n",
       "[50 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dffcbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,1:]\n",
    "y=df.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b447556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis(1=m, 0=b)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis(1=m, 0=b)\n",
       "0                     1\n",
       "1                     1\n",
       "2                     1\n",
       "3                     1\n",
       "4                     1\n",
       "5                     1\n",
       "6                     1\n",
       "7                     1\n",
       "8                     1\n",
       "9                     1\n",
       "10                    1\n",
       "11                    1\n",
       "12                    1\n",
       "13                    1\n",
       "14                    1\n",
       "15                    1\n",
       "16                    1\n",
       "17                    1\n",
       "18                    1\n",
       "19                    0\n",
       "20                    0\n",
       "21                    0\n",
       "22                    1\n",
       "23                    1\n",
       "24                    1\n",
       "25                    1\n",
       "26                    1\n",
       "27                    1\n",
       "28                    1\n",
       "29                    1\n",
       "30                    1\n",
       "31                    1\n",
       "32                    1\n",
       "33                    1\n",
       "34                    1\n",
       "35                    1\n",
       "36                    1\n",
       "37                    0\n",
       "38                    1\n",
       "39                    1\n",
       "40                    1\n",
       "41                    1\n",
       "42                    1\n",
       "43                    1\n",
       "44                    1\n",
       "45                    1\n",
       "46                    0\n",
       "47                    1\n",
       "48                    0\n",
       "49                    0\n",
       "50                    0\n",
       "51                    0\n",
       "52                    0\n",
       "53                    1\n",
       "54                    1\n",
       "55                    0\n",
       "56                    1\n",
       "57                    1\n",
       "58                    0\n",
       "59                    0\n",
       "60                    0\n",
       "61                    0\n",
       "62                    1\n",
       "63                    0\n",
       "64                    1\n",
       "65                    1\n",
       "66                    0\n",
       "67                    0\n",
       "68                    0\n",
       "69                    0\n",
       "70                    1\n",
       "71                    0\n",
       "72                    1\n",
       "73                    1\n",
       "74                    0\n",
       "75                    1\n",
       "76                    0\n",
       "77                    1\n",
       "78                    1\n",
       "79                    0\n",
       "80                    0\n",
       "81                    0\n",
       "82                    1\n",
       "83                    1\n",
       "84                    0\n",
       "85                    1\n",
       "86                    1\n",
       "87                    1\n",
       "88                    0\n",
       "89                    0\n",
       "90                    0\n",
       "91                    1\n",
       "92                    0\n",
       "93                    0\n",
       "94                    1\n",
       "95                    1\n",
       "96                    0\n",
       "97                    0\n",
       "98                    0\n",
       "99                    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a2fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "365201a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 1)\n"
     ]
    }
   ],
   "source": [
    "n=np.arange(1,16)\n",
    "class_acc=np.empty(len(n))\n",
    "test_acc=np.empty(len(n))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23ef3fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "m=0\n",
    "k1=0\n",
    "for i,k in enumerate(n):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    class_acc[i]=knn.score(x_train,y_train)\n",
    "    test_acc[i]=knn.score(x_test,y_test)\n",
    "    if(m<test_acc[i]):\n",
    "        m=test_acc[i]\n",
    "        k1=k\n",
    "        y_predi=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b7a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "650bb0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n, test_acc, label = 'Testing dataset Accuracy')\n",
    "plt.plot(n, class_acc, label = 'Training dataset Accuracy')\n",
    "  \n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f52118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0f78e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of K and its efficiency is 11 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "print(\"The best value of K and its efficiency is\",k1,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36838f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   1]\n",
      " [  5  58]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1831abf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "186c09b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       108\n",
      "           1       0.98      0.92      0.95        63\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b371b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
